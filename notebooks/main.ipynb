{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: \n",
    "* Reward function: \n",
    "* State: \n",
    "* Environment: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T16:58:46.178407Z",
     "start_time": "2021-07-07T16:58:34.361178Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -r ../requirements.txt --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.2'></a>\n",
    "## 2.2. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T17:00:56.233485Z",
     "start_time": "2021-07-07T17:00:54.657807Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload \n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "from src.config import config\n",
    "from src.dataset.cryptodownloader import CryptoDownloader\n",
    "from src.preprocessing.preprocessors import FeatureEngineer\n",
    "from src.preprocessing.data import data_split\n",
    "from src.environment.env_custom import CustomTradingEnv\n",
    "from src.model.models import DRLAgent\n",
    "from src.evaluate.backtest import BackTest\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3 Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T17:00:59.362852Z",
     "start_time": "2021-07-07T17:00:59.358159Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "download_data = False\n",
    "if not os.path.exists(config.DATA_SAVE_DIR):\n",
    "    os.makedirs(config.DATA_SAVE_DIR)\n",
    "    download_data = True\n",
    "# if not os.path.exists(config.TRAINED_MODEL_DIR):\n",
    "#     os.makedirs(config.TRAINED_MODEL_DIR)\n",
    "# if not os.path.exists(config.TENSORBOARD_LOG_DIR):\n",
    "#     os.makedirs(config.TENSORBOARD_LOG_DIR)\n",
    "# if not os.path.exists(config.RESULTS_DIR):\n",
    "#     os.makedirs(config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T17:01:01.530962Z",
     "start_time": "2021-07-07T17:01:01.431819Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_downloader = CryptoDownloader(config.START_DATE, config.END_DATE, config.MULTIPLE_TICKER_8, config.DATA_SAVE_DIR, config.DATA_GRANULARITY)\n",
    "if download_data:    \n",
    "    data_downloader.download_data()\n",
    "df = data_downloader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T17:01:02.172843Z",
     "start_time": "2021-07-07T17:01:02.152116Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-07T17:01:31.046Z"
    }
   },
   "outputs": [],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    use_turbulence=False,\n",
    "                    user_defined_feature = True,\n",
    "                    use_covariance= True\n",
    ")\n",
    "\n",
    "df = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-07T17:01:31.334Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data split: 2020-02-02 to 2020-12-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-07T17:01:31.946Z"
    }
   },
   "outputs": [],
   "source": [
    "train = data_split(df, '2020-02-02','2020-12-31')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment for Portfolio Allocation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-07T17:01:32.426Z"
    }
   },
   "outputs": [],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n",
    "features =  config.TECHNICAL_INDICATORS_SHORTPERIOD + config.TECHNICAL_INDICATORS_LONGPERIOD  + [\"open\", \"close\", 'high', 'low']\n",
    "features += [f\"{feature}_diff\" for feature in features]\n",
    "features += [feature for feature in df.columns if feature.startswith(\"cov_\")]\n",
    "\n",
    "env_kwargs = {\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"max_assets_amount_per_trade\": 100,\n",
    "    \"main_tickers\": config.MULTIPLE_TICKER_8,\n",
    "    \"all_tickers\": config.MULTIPLE_TICKER_8,\n",
    "    \"reward_type\": \"percentage\",\n",
    "    \"discrete_actionspace\": True,\n",
    "    \"comission_value\": 0.01\n",
    "}\n",
    "\n",
    "e_train_gym = CustomTradingEnv(df = train, features=features,**env_kwargs,)\n",
    "\n",
    "env_train, _ = e_train_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-07T17:01:33.862Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "agent = DRLAgent(env = env_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: **A2C**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-07T17:01:34.242Z"
    }
   },
   "outputs": [],
   "source": [
    "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
    "model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS, tensorboard_log = config.TENSORBOARD_LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-07T17:01:34.442Z"
    },
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                                tb_log_name='a2c',\n",
    "                                total_timesteps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: **PPO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-07T17:01:38.006Z"
    }
   },
   "outputs": [],
   "source": [
    "# agent = DRLAgent(env = env_train)\n",
    "# PPO_PARAMS = {\n",
    "#     \"n_steps\": 2048,\n",
    "#     \"ent_coef\": 0.005,\n",
    "#     \"learning_rate\": 0.0001,\n",
    "#     \"batch_size\": 128,\n",
    "# }\n",
    "# model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-07T17:01:38.194Z"
    }
   },
   "outputs": [],
   "source": [
    "# trained_ppo = agent.train_model(model=model_ppo, \n",
    "#                              tb_log_name='ppo',\n",
    "#                              total_timesteps=80000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trading\n",
    "Assume that we have $1,000,000 initial capital at 2021-01-01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-07T17:01:38.542Z"
    }
   },
   "outputs": [],
   "source": [
    "trade = data_split(df,config.START_TEST_DATE, config.END_DATE)\n",
    "e_trade_gym = CustomTradingEnv(df = trade, **env_kwargs, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-07T17:01:38.714Z"
    }
   },
   "outputs": [],
   "source": [
    "trade.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-07T17:01:38.878Z"
    }
   },
   "outputs": [],
   "source": [
    "trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-07T17:01:39.042Z"
    }
   },
   "outputs": [],
   "source": [
    "allocations, transactions, allocation_values = DRLAgent.DRL_prediction(model=trained_a2c,\n",
    "                        environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-07T17:01:39.222Z"
    }
   },
   "outputs": [],
   "source": [
    "allocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-07T17:01:39.402Z"
    }
   },
   "outputs": [],
   "source": [
    "transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-07T17:01:39.579Z"
    }
   },
   "outputs": [],
   "source": [
    "allocation_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-07T17:01:39.927Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload \n",
    "bat = BackTest(trained_a2c, e_trade_gym)\n",
    "bat.create_summary(allocations, allocation_values, transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-07T17:01:40.099Z"
    }
   },
   "outputs": [],
   "source": [
    "bat.plot_return_against_hold(allocation_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-07T17:01:40.262Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload \n",
    "from src.evaluate.time_series_validation import TimeSeriesValidation\n",
    "tsv = TimeSeriesValidation(num_splits=5, total_timesteps_model=1000, with_graphs=False)\n",
    "\n",
    "model_name = \"a2c\"\n",
    "model_params = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
    "\n",
    "stock_dimension = len(df.tic.unique())\n",
    "state_space = stock_dimension\n",
    "features =  config.TECHNICAL_INDICATORS_SHORTPERIOD + config.TECHNICAL_INDICATORS_LONGPERIOD + [\"open\", \"close\", 'high', 'low']\n",
    "features += [f\"{feature}_diff\" for feature in features]\n",
    "features += [feature for feature in df.columns if feature.startswith(\"cov_\")]\n",
    "\n",
    "env_params = {\n",
    "    \"initial_amount\": 1000000, \n",
    "    \"max_assets_amount_per_trade\": 100, \n",
    "    \"main_tickers\": df.tic.unique(),\n",
    "    \"all_tickers\": df.tic.unique(),\n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"comission_value\": 0.01,\n",
    "    \"features\":features\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "results = tsv.run(df, env_params, model_name, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-07T17:01:40.430Z"
    }
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b9756390c5f4d66a4da61aa8031b3444172eaaeb19510c727dc3b143db836ba"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('TradingRLBot': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}