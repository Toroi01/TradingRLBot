{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: \n",
    "* Reward function: \n",
    "* State: \n",
    "* Environment: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T21:23:56.595180Z",
     "start_time": "2021-06-11T21:23:34.568491Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.2'></a>\n",
    "## 2.2. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T11:18:34.635918Z",
     "start_time": "2021-06-13T11:18:34.560441Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload \n",
    "import pandas as pd\n",
    "from config import config\n",
    "from dataset.download_dataset.cryptodownloader_binance import CryptoDownloader_binance\n",
    "from preprocessing.preprocessors import FeatureEngineer\n",
    "from preprocessing.data import data_split\n",
    "from env.env_custom import CustomTradingEnv\n",
    "from model.models import DRLAgent\n",
    "from trade.backtest import BackTest\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# from trade.backtest import backtest_stats, backtest_plot, get_daily_return, get_baseline,convert_daily_return_to_pyfolio_ts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3 Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T11:18:35.041869Z",
     "start_time": "2021-06-13T11:18:35.037652Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "download_data = False\n",
    "if not os.path.exists(config.DATA_SAVE_DIR):\n",
    "    os.makedirs(config.DATA_SAVE_DIR)\n",
    "    download_data = True\n",
    "if not os.path.exists(config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(config.RESULTS_DIR):\n",
    "    os.makedirs(config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T11:18:35.520541Z",
     "start_time": "2021-06-13T11:18:35.446947Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_downloader = CryptoDownloader_binance(config.START_DATE, config.END_DATE, config.MULTIPLE_TICKER_8, config.DATA_SAVE_DIR, config.DATA_GRANULARITY)\n",
    "if download_data:    \n",
    "    data_downloader.download_data()\n",
    "df = data_downloader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T11:19:43.382372Z",
     "start_time": "2021-06-13T11:18:36.080062Z"
    }
   },
   "outputs": [],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    use_turbulence=False,\n",
    "                    user_defined_feature = True)\n",
    "\n",
    "df = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add covariance matrix as states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T11:38:26.239892Z",
     "start_time": "2021-06-13T11:37:17.779572Z"
    }
   },
   "outputs": [],
   "source": [
    "# add covariance matrix as states\n",
    "df=df.sort_values(['date','tic'],ignore_index=True)\n",
    "df.index = df.date.factorize()[0]\n",
    "\n",
    "cov_list = []\n",
    "# look back is one year\n",
    "lookback=252\n",
    "for i in range(lookback,len(df.index.unique())):\n",
    "  data_lookback = df.loc[i-lookback:i,:]\n",
    "  price_lookback=data_lookback.pivot_table(index = 'date',columns = 'tic', values = 'close')\n",
    "  return_lookback = price_lookback.pct_change().dropna()\n",
    "  covs = return_lookback.cov().values \n",
    "  cov_list.append(covs)\n",
    "  \n",
    "df_cov = pd.DataFrame({'date':df.date.unique()[lookback:],'cov_list':cov_list})\n",
    "df = df.merge(df_cov, on='date')\n",
    "df = df.sort_values(['date','tic']).reset_index(drop=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T11:38:26.309433Z",
     "start_time": "2021-06-13T11:38:26.241763Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data split: 2020-01-01 to 2020-12-31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T11:38:43.501298Z",
     "start_time": "2021-06-13T11:38:43.449536Z"
    }
   },
   "outputs": [],
   "source": [
    "train = data_split(df, '2020-02-02','2020-12-31')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment for Portfolio Allocation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T11:38:44.076465Z",
     "start_time": "2021-06-13T11:38:44.050273Z"
    }
   },
   "outputs": [],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n",
    "features = config.TECHNICAL_INDICATORS_LIST + [\"open\", \"close\", 'high', 'low']\n",
    "features += [f\"{feature}_diff\" for feature in features]\n",
    "\n",
    "env_kwargs = {\n",
    "    \"initial_amount\": 1000000, \n",
    "    \"technical_indicator_list\": features, \n",
    "    \"max_assets_amount_per_trade\": 100, \n",
    "    \"main_tickers\": train.tic.unique(),\n",
    "    \"all_tickers\": train.tic.unique(),\n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"comission_value\": 0.01\n",
    "    \n",
    "}\n",
    "\n",
    "e_train_gym = CustomTradingEnv(df = train, **env_kwargs)\n",
    "\n",
    "env_train, _ = e_train_gym.get_sb_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T11:38:44.883715Z",
     "start_time": "2021-06-13T11:38:44.881326Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "agent = DRLAgent(env = env_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: **A2C**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T11:38:45.701566Z",
     "start_time": "2021-06-13T11:38:45.693547Z"
    }
   },
   "outputs": [],
   "source": [
    "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
    "model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T11:38:55.634295Z",
     "start_time": "2021-06-13T11:38:46.742139Z"
    },
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                                tb_log_name='a2c',\n",
    "                                total_timesteps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: **PPO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T11:27:54.250864Z",
     "start_time": "2021-06-13T11:27:54.248940Z"
    }
   },
   "outputs": [],
   "source": [
    "# agent = DRLAgent(env = env_train)\n",
    "# PPO_PARAMS = {\n",
    "#     \"n_steps\": 2048,\n",
    "#     \"ent_coef\": 0.005,\n",
    "#     \"learning_rate\": 0.0001,\n",
    "#     \"batch_size\": 128,\n",
    "# }\n",
    "# model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T11:27:54.255492Z",
     "start_time": "2021-06-13T11:27:54.253557Z"
    }
   },
   "outputs": [],
   "source": [
    "# trained_ppo = agent.train_model(model=model_ppo, \n",
    "#                              tb_log_name='ppo',\n",
    "#                              total_timesteps=80000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trading\n",
    "Assume that we have $1,000,000 initial capital at 2021-01-01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T11:27:54.278821Z",
     "start_time": "2021-06-13T11:27:54.257392Z"
    }
   },
   "outputs": [],
   "source": [
    "trade = data_split(df,config.START_TEST_DATE, config.END_DATE)\n",
    "e_trade_gym = CustomTradingEnv(df = trade, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T11:27:54.284332Z",
     "start_time": "2021-06-13T11:27:54.280579Z"
    }
   },
   "outputs": [],
   "source": [
    "trade.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T11:27:54.312204Z",
     "start_time": "2021-06-13T11:27:54.285887Z"
    }
   },
   "outputs": [],
   "source": [
    "trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T11:28:19.087724Z",
     "start_time": "2021-06-13T11:27:54.313685Z"
    }
   },
   "outputs": [],
   "source": [
    "allocations, transactions, allocation_values = DRLAgent.DRL_prediction(model=trained_a2c,\n",
    "                        environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T11:28:19.106007Z",
     "start_time": "2021-06-13T11:28:19.092256Z"
    }
   },
   "outputs": [],
   "source": [
    "allocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T11:28:19.116616Z",
     "start_time": "2021-06-13T11:28:19.107622Z"
    }
   },
   "outputs": [],
   "source": [
    "transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T11:28:55.911401Z",
     "start_time": "2021-06-13T11:28:55.892181Z"
    }
   },
   "outputs": [],
   "source": [
    "allocation_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T11:29:27.686869Z",
     "start_time": "2021-06-13T11:29:24.147736Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload \n",
    "bat = BackTest(trained_a2c, e_trade_gym)\n",
    "bat.create_summary(allocations, allocation_values, transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-13T11:29:27.920046Z",
     "start_time": "2021-06-13T11:29:27.688629Z"
    }
   },
   "outputs": [],
   "source": [
    "bat.plot_return_against_hold(allocation_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b9756390c5f4d66a4da61aa8031b3444172eaaeb19510c727dc3b143db836ba"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('TradingRLBot': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}